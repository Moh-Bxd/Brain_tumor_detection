{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Moh-Bxd/Brain_tumor_detection/blob/main/Brain_tumor_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkbxEiV_vOdn"
      },
      "source": [
        "# Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOEt1hBu8b_"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzWRKghdoRqH",
        "outputId": "6094baed-3295-46bd-e359-2a9097459f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brain-tumor-segmentation.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ./brain-tumor-segmentation.zip\n",
            "replace images/1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! kaggle datasets download nikhilroxtomar/brain-tumor-segmentation\n",
        "! unzip ./brain-tumor-segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlIMJpiBGxce"
      },
      "source": [
        "# Import packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fOsGNduQHQn5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF7DadElHqLg"
      },
      "source": [
        "# Setup Data Dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThVCEaryFolV"
      },
      "source": [
        "# importing dataset from kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JkbFecOJK3l",
        "outputId": "9a5298a0-6293-42c9-e248-0deceaff0d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3064, 128, 128, 3)\n",
            "(3064, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "image_path = \"./images\"\n",
        "mask_path = \"./masks\"\n",
        "\n",
        "def load_data(image_path, mask_path, target_size=(128, 128)):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_name in os.listdir(image_path):\n",
        "        img = cv2.imread(os.path.join(image_path, img_name))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        # Resize image to target size\n",
        "        img = cv2.resize(img, target_size)\n",
        "\n",
        "        images.append(img)\n",
        "\n",
        "        mask = cv2.imread(os.path.join(mask_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Resize mask to target size\n",
        "        mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        mask = np.expand_dims(mask , axis=-1)\n",
        "\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "images, masks = load_data(image_path, mask_path)\n",
        "print(images.shape)\n",
        "print(masks.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD6BJhAmNAKM"
      },
      "source": [
        "# Spliting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IhNPve3NDuB",
        "outputId": "25afabab-dcd7-40ac-e0b9-def50dc18bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2144, 128, 128, 3)\n",
            "(2144, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "train_images , temp_images , train_labels , temp_labels = train_test_split(images, masks, test_size=0.3, random_state=42)\n",
        "test_images , val_images , test_labels , val_labels = train_test_split(temp_images, temp_labels , test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr16lgB5w6m9"
      },
      "source": [
        "# convert everything to tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP9h6Ic2v9M1",
        "outputId": "995e4180-f0af-49f9-e33f-65b376faf815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2144, 128, 128, 3)\n",
            "(2144, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "train_images_tensor = tf.convert_to_tensor(train_images)\n",
        "test_images_tensor = tf.convert_to_tensor(test_images)\n",
        "val_images_tensor = tf.convert_to_tensor(val_images)\n",
        "\n",
        "train_labels_tensor = tf.convert_to_tensor(train_labels)\n",
        "test_labels_tensor = tf.convert_to_tensor(test_labels)\n",
        "val_labels_tensor = tf.convert_to_tensor(val_labels)\n",
        "\n",
        "print(train_images_tensor.shape)\n",
        "print(train_labels_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYECI1kFuvqk"
      },
      "source": [
        "# resize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_kAbfaE2vdRf"
      },
      "outputs": [],
      "source": [
        "#input image and input mask must be a tensor\n",
        "def resize(input_images, input_masks):\n",
        "  for input_image , input_mask in zip(input_images, input_masks):\n",
        "\n",
        "    if input_image.ndim == 2:\n",
        "      input_image = tf.expand_dims(input_image, axis=-1)\n",
        "    if input_mask.ndim == 2:\n",
        "      input_mask = tf.expand_dims(input_mask, axis=-1)\n",
        "\n",
        "\n",
        "    input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "    input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "\n",
        "\n",
        "  return input_images, input_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eENee3rAxAWi"
      },
      "outputs": [],
      "source": [
        "train_images , train_labels = resize(train_images_tensor,train_labels_tensor)\n",
        "test_images , test_labels = resize(test_images_tensor,test_labels_tensor)\n",
        "val_images , val_labels = resize(val_images_tensor,val_labels_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbtRRn5fyUJ3"
      },
      "source": [
        "# Augment the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZjTz4Cioycfo"
      },
      "outputs": [],
      "source": [
        "def augment(input_images, input_masks):\n",
        "   if tf.random.uniform(()) > 0.5:\n",
        "       # Random flipping of the image and mask\n",
        "       for input_image , input_mask  in zip(input_images, input_masks):\n",
        "        if input_image.ndim == 2:\n",
        "            input_image = tf.expand_dims(input_image, axis=-1)\n",
        "        if input_mask.ndim == 2:\n",
        "            input_mask = tf.expand_dims(input_mask, axis=-1)\n",
        "\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "   return input_images, input_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TL4bBipyePU",
        "outputId": "4f3435e2-5692-4431-c395-a8bae382c0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2144, 128, 128, 3)\n",
            "(2144, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "#augment only the training data\n",
        "train_images , train_labels = augment(train_images,train_labels)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFcPFUsIy725"
      },
      "source": [
        "# normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b0tJQzDuy_1x"
      },
      "outputs": [],
      "source": [
        "def normalize(input_images, input_masks):\n",
        "  for input_image , input_mask in zip(input_images, input_masks):\n",
        "\n",
        "\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask -= 1\n",
        "  return input_images, input_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_-ASfrAzDd4",
        "outputId": "e0d9d4af-6f7f-4382-bfc9-b62d3c702f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2144, 128, 128, 3)\n",
            "(2144, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "train_images , train_labels = normalize(train_images,train_labels)\n",
        "test_images , test_labels = normalize(test_images,test_labels)\n",
        "val_images , val_labels = normalize(val_images,val_labels)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkMAiEm84re"
      },
      "source": [
        "# Building u-net Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5k3fmmFj8-Lh"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ue7fxgCj9I4_"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JoFUYsXp9PSk"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXt8tZWP-4pX"
      },
      "source": [
        "# creating the u-net builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fIYfBXV8_Ak1"
      },
      "outputs": [],
      "source": [
        "def build_unet_model():\n",
        "  inputs = layers.Input(shape=(128,128,3))\n",
        "   # encoder: contracting path - downsample\n",
        "   # 1 - downsample\n",
        "  f1, p1 = downsample_block(inputs, 64)\n",
        "   # 2 - downsample\n",
        "  f2, p2 = downsample_block(p1, 128)\n",
        "   # 3 - downsample\n",
        "  f3, p3 = downsample_block(p2, 256)\n",
        "   # 4 - downsample\n",
        "  f4, p4 = downsample_block(p3, 512)\n",
        "   # 5 - bottleneck\n",
        "  bottleneck = double_conv_block(p4, 1024)\n",
        "   # decoder: expanding path - upsample\n",
        "   # 6 - upsample\n",
        "  u6 = upsample_block(bottleneck, f4, 512)\n",
        "   # 7 - upsample\n",
        "  u7 = upsample_block(u6, f3, 256)\n",
        "   # 8 - upsample\n",
        "  u8 = upsample_block(u7, f2, 128)\n",
        "   # 9 - upsample\n",
        "  u9 = upsample_block(u8, f1, 64)\n",
        "   # outputs\n",
        "  outputs = layers.Conv2D(3, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "   # unet model with Keras Functional API\n",
        "  unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "  return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fnx5iv9EABcI"
      },
      "outputs": [],
      "source": [
        "unet_model = build_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znyyXJyOALlN"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PLoting some Images"
      ],
      "metadata": {
        "id": "snnaucDsGI5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(val_labels[78])"
      ],
      "metadata": {
        "id": "ERUhZ1BnJVoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b59Mp_qA6Tt"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5diOjpA395",
        "outputId": "8d3c50e0-9938-460a-aa5a-eeea852e725f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2144, 128, 128, 1)\n",
            "(644, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=\"accuracy\")\n",
        "\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ0e8fDvFh_h",
        "outputId": "e52b6ce2-f628-451d-e93b-7c02c6afff64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/17 [===========================>..] - ETA: 1s - loss: nan - accuracy: 0.9323"
          ]
        }
      ],
      "source": [
        "unet_model.fit(\n",
        "    x=train_images,\n",
        "    y=train_labels,\n",
        "    batch_size=128,\n",
        "    epochs=20,\n",
        "    verbose='auto',\n",
        "    callbacks=None,\n",
        "    validation_split=0.0,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIZ3yJ3UlJ2xBKlhmA6B0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}